Investigating Grokking at the Edge of Linear Separability
REading abstaract,

Asked Chat
 Can you explain what the origin is in this paper on Linear seperability?

 Even though a perfect generalizing solution always exists,
we prove the implicit bias of the logisitc loss will cause the model to overfit if the training data
is linearly separable from the origin. For training sets that are not separable from the origin, the
model will always generalize perfectly asymptotically, but overfitting may occur at early stages of
training.

Answer:
In the context of this paper on linear separability, the term "origin" refers to the point in the feature space where all the feature values are zero. In simple terms, it's the point (0,0,...,0) in a multi-dimensional space.

Hereâ€™s a breakdown of the key ideas in the passage:

    Linear Separability from the Origin: This means that the data points can be perfectly divided by a linear boundary, such as a line or hyperplane, that doesn't pass through the origin. In other words, the two classes of data (for classification problems) can be separated by a straight line, but the line isn't constrained to go through the point (0,0,...,0).

    Effect on Model Behavior:

        If the data is linearly separable from the origin, the implicit bias of the logistic loss will cause the model to overfit. This is because when the model has a perfect separation between classes, it tends to keep adjusting the weights excessively, even after it has already found a solution that separates the classes. This overfitting can happen since logistic regression keeps pushing for a higher confidence on predictions, even after separating the data.

        On the other hand, if the data is not separable from the origin, the model will eventually generalize perfectly (asymptotically). This means that the model will, over time, converge to a solution that performs well on unseen data. However, overfitting might still occur in the early stages of training before the model stabilizes and finds a good boundary.

In summary, the reference to the "origin" highlights whether the linear boundary used to classify the data passes through the point where all features are zero, and this has implications on how the model fits and generalizes.



I know know whtat I don't understand why an origin is necessary or the setup of the paper. I know there are two classes and the model is only using a singl line to try to serpate them. 
I don't know how it generates the line. It could indicate the tipping point where the model always chooses class 0 over class 1.


To get to the point where I can make a model in colab and display that I understand the concept, I need to be able to generate a environment like the paper and apply whatever technique they are suggesting.

Potential insite: It oculd be that this binary classificaiotn is a toy model. Multi classification will require a lot more dimensions but the principle of how the classes are seperated may be the same. I say this because in higher dimensions there are many more "right" angles. 

Potential insite: If I can identify uses cases for this paper automatically in certain AI models, such as when a model is very good in trainig at a task but terrible in implementation, I could use a search function to identify which classes are confusing and computationally detect if Grokking will work. 

From what I understand, the data must be linearly seperatable from the origin. I other word, the origin must be roughly in the center of the data distribution. if it is far outside or highly skewed, grokking will likely never occure. 


While its seems the paper's discovery is very simple: When trying to classify binary classes in a isotropic normal distrbution with very noisy features. Assumming number of features < 1/2 * N, Grokking will likely occure. 
But there seems to be so much more observations in the paper that seem unrelated to teh conlcusins given. Some appear to focus on the time to convergence and how to calculate it. 

2024.10.21
I want to ask the AI to generate code that will recreate the white paper's experument. 
I need to make sure the code it generates accratly reflects the white paper experument. 
I am thinking about asking the aI to evaluate it's own code by giving it a parapgraph of
the whitepaper to check it's work.

Are the distributions garenteed to be able to be seperated?

2024.10.22
I am using this code to run experuments to replicate grokking:
  
  '''
  import numpy as np
  import matplotlib.pyplot as plt
  from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
  
  # Sigmoid function for logistic regression
  def sigmoid(z):
      return 1 / (1 + np.exp(-z))
  
  # Cross-entropy loss
  def cross_entropy_loss(S, b, X, y):
      z = X.dot(S) + b
      return np.mean(np.log(1 + np.exp(z)))
  
  # Compute accuracy
  def accuracy(S, b, X, y):
      preds = X.dot(S) + b
      predicted_labels = np.heaviside(-preds, 0)  # Heaviside function for accuracy calculation
      return np.mean(predicted_labels == y)
  
  # Gradient Descent Function
  def logistic_regression_gd(N, d, sigma, nu, num_steps):
      """
      Perform logistic regression using gradient descent.
      
      Parameters:
      - N (int): Number of points (samples)
      - d (int): Number of dimensions (features)
      - sigma (float): Standard deviation of the feature distribution
      - nu (float): Learning rate for gradient descent
      - num_steps (int): Number of steps to run the gradient descent
      
      Returns:
      - losses (list): List of cross-entropy losses over training
      - accuracies (list): List of accuracies over training
      - confusion_matrix: Confusion matrix of the final predictions
      """
      # Generate data
      X = np.random.normal(0, sigma, (N, d))  # N samples, each with d features
      true_labels = np.ones(N)  # All labels are 1 (can modify for binary classification)
  
      # Initialize weights and bias
      S = np.random.randn(d)  # Weight vector of size d
      b = np.random.randn()    # Bias scalar
  
      # Containers to store loss and accuracy
      losses = []
      accuracies = []
  
      # Gradient descent loop
      for step in range(num_steps):
          # Compute the prediction
          z = X.dot(S) + b
          y_pred = sigmoid(z)
          
          # Compute the gradients
          gradient_S = X.T.dot(y_pred - true_labels) / N  # Gradient w.r.t S
          gradient_b = np.sum(y_pred - true_labels) / N   # Gradient w.r.t b
          
          # Update weights and bias
          S -= nu * gradient_S
          b -= nu * gradient_b
          
          # Calculate and store loss and accuracy
          loss = cross_entropy_loss(S, b, X, true_labels)
          acc = accuracy(S, b, X, true_labels)
          losses.append(loss)
          accuracies.append(acc)
          
          if step % 100 == 0:
              print(f"Step {step}, Loss: {loss:.4f}, Accuracy: {acc:.4f}")
      
      # Final predictions for confusion matrix
      preds = X.dot(S) + b
      predicted_labels = np.heaviside(-preds, 0)  # Heaviside function threshold for binary classification
  
      # Confusion matrix
      cm = confusion_matrix(true_labels, predicted_labels)
      
      return losses, accuracies, cm
  
  # Function to plot the results
  def plot_results(losses, accuracies, cm):
      # Plotting the loss and accuracy over time
      plt.figure(figsize=(12, 5))
  
      # Loss curve
      plt.subplot(1, 2, 1)
      plt.plot(losses, label="Loss")
      plt.title("Cross-Entropy Loss over Time")
      plt.xlabel("Iteration")
      plt.ylabel("Loss")
      plt.legend()
  
      # Accuracy curve
      plt.subplot(1, 2, 2)
      plt.plot(accuracies, label="Accuracy", color='orange')
      plt.title("Accuracy over Time")
      plt.xlabel("Iteration")
      plt.ylabel("Accuracy")
      plt.legend()
  
      plt.tight_layout()
      plt.show()
  
      # Display confusion matrix
      disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])
      disp.plot()
      plt.title("Confusion Matrix")
      plt.show()
  
  # Example usage
  N = 1000          # Number of points
  d = 500           # Number of dimensions
  sigma = 1.0       # Feature standard deviation
  nu = 0.0001         # Learning rate
  num_steps = 1000  # Number of steps
  
  # Run gradient descent logistic regression
  losses, accuracies, cm = logistic_regression_gd(N, 5, sigma, nu, num_steps)
  
  # Plot the results
  plot_results(losses, accuracies, cm)
  
  # Run gradient descent logistic regression
  losses, accuracies, cm = logistic_regression_gd(N, 460, sigma, nu, num_steps)
  
  # Plot the results
  plot_results(losses, accuracies, cm)
  
  # Run gradient descent logistic regression
  losses, accuracies, cm = logistic_regression_gd(N, 540, sigma, nu, num_steps)
  
  # Plot the results
  plot_results(losses, accuracies, cm)
'''

So far it has the strange effect if decreasing the accuracy and increaseing the loss every step. 

Its unclear why the loss is going donw but the accuracy remains 50%ish. it's like there is no way to seperate the data. 

2024.10.30
10:21am
I asked Chat if the above code and result of Step 900, Loss: 9.0313, Accuracy: 0.5060 was an example of grokking, it denied and said that the 50% accuracy inicated  no grokking had occured. 
I then asked it "Can you edit the model to use a simpler binary classification task where grokking is more likely to be observed."
Chat responded with an example of grokking. AFter I ran the code, I then asked itt to add scatterplots to it. 
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Sigmoid function for logistic regression
def sigmoid(z):
    return 1 / (1 + np.exp(-z))

# Cross-entropy loss
def cross_entropy_loss(S, b, X, y):
    z = X.dot(S) + b
    y_pred = sigmoid(z)
    return -np.mean(y * np.log(y_pred + 1e-9) + (1 - y) * np.log(1 - y_pred + 1e-9))

# Compute accuracy
def accuracy(S, b, X, y):
    preds = sigmoid(X.dot(S) + b) >= 0.5
    return np.mean(preds == y)

# Logistic Regression with Gradient Descent
def logistic_regression_gd(N, d, nu, num_steps):
    # Generate simple binary data (2D Gaussian clusters)
    X_class0 = np.random.normal(loc=-1, scale=0.5, size=(N//2, d))
    X_class1 = np.random.normal(loc=1, scale=0.5, size=(N//2, d))
    X = np.vstack((X_class0, X_class1))
    y = np.array([0] * (N // 2) + [1] * (N // 2))
    
    # Initialize weights and bias
    S = np.random.randn(d)
    b = np.random.randn()

    # Containers for tracking loss and accuracy over time
    losses = []
    accuracies = []

    for step in range(num_steps):
        # Predictions and gradients
        z = X.dot(S) + b
        y_pred = sigmoid(z)
        gradient_S = X.T.dot(y_pred - y) / N
        gradient_b = np.sum(y_pred - y) / N

        # Update weights and bias
        S -= nu * gradient_S
        b -= nu * gradient_b

        # Calculate loss and accuracy
        loss = cross_entropy_loss(S, b, X, y)
        acc = accuracy(S, b, X, y)
        losses.append(loss)
        accuracies.append(acc)

        if step % 100 == 0:
            print(f"Step {step}, Loss: {loss:.4f}, Accuracy: {acc:.4f}")

    # Final predictions and confusion matrix
    final_preds = sigmoid(X.dot(S) + b) >= 0.5
    cm = confusion_matrix(y, final_preds)

    return losses, accuracies, cm, S, b, X, y

# Function to plot the results, including decision boundary
def plot_results(losses, accuracies, cm, S, b, X, y):
    # Plot Loss and Accuracy
    plt.figure(figsize=(15, 5))
    plt.subplot(1, 3, 1)
    plt.plot(losses, label="Loss")
    plt.title("Cross-Entropy Loss over Time")
    plt.xlabel("Iteration")
    plt.ylabel("Loss")
    plt.legend()
    plt.show()

    plt.subplot(1, 3, 2)
    plt.plot(accuracies, label="Accuracy", color='orange')
    plt.title("Accuracy over Time")
    plt.xlabel("Iteration")
    plt.ylabel("Accuracy")
    plt.legend()
    plt.show()

    # Scatter plot with Decision Boundary
    plt.figure(figsize=(7, 7))
    plt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], label="Class 0", alpha=0.5, color='blue')
    plt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], label="Class 1", alpha=0.5, color='orange')

    # Plotting the decision boundary
    x_values = np.linspace(X[:, 0].min(), X[:, 0].max(), 100)
    y_values = -(S[0] * x_values + b) / S[1]
    plt.plot(x_values, y_values, color="black", label="Decision Boundary")
    plt.xlabel("Feature 1")
    plt.ylabel("Feature 2")
    plt.title("Data Points and Decision Boundary")
    plt.legend()
    plt.show()

    # Confusion Matrix Display
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])
    disp.plot()
    plt.title("Confusion Matrix")
    plt.show()

# Example usage with a simpler binary classification task
N = 1000         # Number of points
d = 2            # Number of features (simpler binary task)
nu = 0.01        # Learning rate
num_steps = 2000 # Number of steps for observing grokking

# Run logistic regression with gradient descent
losses, accuracies, cm, S, b, X, y = logistic_regression_gd(N, d, nu, num_steps)

# Plot the results
plot_results(losses, accuracies, cm, S, b, X, y)


